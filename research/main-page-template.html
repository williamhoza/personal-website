<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <link rel="stylesheet" href="/temml/Temml-Latin-Modern.css">
        <script src="/temml/temml.min.js"></script>
        <script src="/temml/auto-render.min.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research | William Hoza</title>
        <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,700&amp;display=swap" rel="stylesheet">
        <link rel="stylesheet" href="/main.css">
        <link rel="stylesheet" href="main-page.css">
    </head>
    <body>
        <main>
            <article>
                <p><a href="/">Back to my homepage</a></p>
                <hr>
                <h1>Research</h1>
                <p>
                    I study <strong>computational complexity theory</strong>. I'm especially interested in pseudorandomness, derandomization, and circuit complexity. Click <a href="research-summary-2024-02-23.pdf">here</a> to see a poster-style image from February 2024 summarizing my research areas.
                </p>
                <details>
                    <summary>Click here for a short explanation of what "derandomization" means (for curious outsiders).</summary>
                    <div class="indent">
                        <p>
                            Some algorithms use randomness to solve computational problems. For example, one of the best methods known for finding a large prime number is to pick a large number at random, check if it's prime, and try again if necessary.</p><p>You can think of randomness as a scarce computational resource â€” a type of algorithmic "fuel." Randomized algorithms are okay, but all else being equal, an algorithm that uses <em>fewer</em> random bits is better than an algorithm that uses more random bits, just like a faster algorithm is better than a slower algorithm, or a car that uses less gasoline is better than a car that uses more gasoline. Algorithms that don't use any randomness ("deterministic" algorithms) are best of all. For example, it would be nice to have a fast deterministic algorithm for finding large prime numbers. "Derandomization" is the art of converting randomized algorithms into deterministic algorithms.</p><p>One approach for using fewer random bits is to design <em>pseudorandom generators</em>, which use a small number of random bits to generate a long sequence of bits that "look random" and can often be used as a substitute for truly random bits. I'm especially interested in pseudorandom generators that are <em>provably</em> correct.
                        </p>
                    </div>
                </details>
                <p>
                    My research papers are listed below. If you have a question or comment, please send me an <a href="mailto:williamhoza@uchicago.edu">email</a>! Like most researchers, I like getting emails about my work.
                </p>
                <hr>
                <h2>Surveys</h2>
                <data value="SURVEY-LIST"></data>
                <hr>
                <h2>Ordinary research papers</h2>
                <data value="PAPER-LIST"></data>
                <hr>
                <h2 style="display:inline;">Dissertation: </h2> <data value="DISSERTATION"></data>
                <hr>
                <p>
                    I'm grateful for all the mentorship I've received over the years, especially from <a href="http://www.cs.utexas.edu/~diz/">David Zuckerman</a> (my graduate advisor), <a href="https://www.avishaytal.org/">Avishay Tal</a> (my postdoc mentor), and <a href="http://users.cms.caltech.edu/~schulman/">Leonard Schulman</a> and <a href="http://users.cms.caltech.edu/~umans/">Chris Umans</a> (my undergraduate research mentors).
                </p>
            </article>
        </main>
        <script src="/temml/call-auto-render.js"></script>
        <script data-goatcounter="https://williamhoza.goatcounter.com/count" src="//gc.zgo.at/count.js" async=""></script>
    </body>
</html>