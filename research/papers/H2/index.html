<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<link href="/temml/Temml-Latin-Modern.css" rel="stylesheet"/>
<script src="/temml/temml.min.js"></script>
<script src="/temml/auto-render.min.js"></script>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>
Typically-Correct Derandomization for Small Time and Space
</title>
<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,700&amp;display=swap" rel="stylesheet"/>
<link href="/main.css" rel="stylesheet"/>
</head>
<body>
<main>
<article>
<p>
<a href="/research/">
            Back to list of papers
          </a>
</p>
<hr/>
<h1>
Typically-Correct Derandomization for Small Time and Space
</h1>
<p>
By William M. Hoza
</p>
<hr/>
<p>
          Read the paper: <a href="https://arxiv.org/abs/1711.00565">arXiv</a> • <a href="https://doi.org/10.4230/LIPIcs.CCC.2019.9">CCC proceedings</a>
</p>
<details>
<summary>Abstract (for specialists)</summary>
<div class="indent">
<p>
        Suppose a language $L$ can be decided by a bounded-error randomized algorithm that runs in space $S$ and time $n \cdot \text{poly}(S)$. We give a randomized algorithm for $L$ that still runs in space $O(S)$ and time $n \cdot \text{poly}(S)$ that uses only $O(S)$ random bits; our algorithm has a low failure probability on all but a negligible fraction of inputs of each length. As an immediate corollary, there is a deterministic algorithm for $L$ that runs in space $O(S)$ and succeeds on all but a negligible fraction of inputs of each length. We also give several other complexity-theoretic applications of our technique.
    </p>
</div>
</details>
<details>
<summary>Not-so-abstract (for curious outsiders)</summary>
<p>⚠️ <em>This summary might gloss over some important details.</em></p>
<div class="indent" value="NOT-SO-ABSTRACT">
<p>
        A "randomized" algorithm tosses coins to make decisions, whereas a "deterministic" algorithm doesn't use any randomness. Most theoretical computer scientists believe that if a problem can be solved by a randomized algorithm, then it can also be solved by a deterministic algorithm that uses about the same amount of time and memory. But nobody knows how to prove it. In this paper, we prove that if a problem can be solved by a fast randomized algorithm, then it can also be solved by a deterministic algorithm that uses about the same amount of memory, with the caveat that the deterministic algorithm might give the wrong answer on a tiny fraction of inputs.
    </p>
</div>
</details>
<p>

    I posted a manuscript online in November 2017; I presented the paper at CCC in July 2019. The arXiv version and the CCC proceedings version are the same except for formatting.

</p>
<hr/><p>Expository material:</p><div class="expository" value="EXPOSITORY">
<iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/PxiCmJG4h5E"></iframe>
<p>
<a href="https://youtu.be/PxiCmJG4h5E">Video</a> from my presentation at CCC (July 2019). Here are the <a href="CCC-slides.pdf">slides</a> from that presentation. See also these <a href="israel-slides.pdf">longer slides</a> from my presentation at HUJI's Theory of Computer Science Seminar (March 2018); I used very similar slides for my presentations at Weizmann Institute's Foundations of Computer Science Seminar (March 2018) and TAU's Theory of Computation Seminar (March 2018).
    </p>
</div>
<hr/>



</article>
</main>
<script src="/temml/call-auto-render.js"></script>
<script async="" data-goatcounter="https://williamhoza.goatcounter.com/count" src="//gc.zgo.at/count.js"></script>
</body>
</html>