<p>
  This paper is about the value of time for computation. If we slightly increase our time budget, how much extra computational power do we gain?
</p>

<p>
  To be more specific, we study a model of fast parallel algorithms called "$\mathsf{AC}^0$ circuits." An $\mathsf{AC}^0$ circuit is a network of AND gates, OR gates, NOT gates, and input variables connected by wires. You can assign binary values to the input variables. The values feed into whatever gates are connected to the variables. The outputs of those gates feed into other gates, which feed into other gates, and so on, until eventually the circuit produces a binary output. The "depth" of the circuit is the maximum number of AND and OR gates on any path from an input variable to the output gate, which can be considered a measure of the amount of time that the computation takes. The "size" of the circuit is the total number of AND and OR gates, which is a measure of the total amount of work that goes into the computation.
</p>

<p>
  In the paper, we show that for every $d$, there is a computational problem such that on the one hand, the problem can be solved by small $\mathsf{AC}^0$ circuits of depth $d + 3$, but on the other hand, the problem cannot be solved by $\mathsf{AC}^0$ circuits of depth $d$ unless they are enormous. In fact, depth-$d$ circuits that are trying to solve this problem and that are not enormous cannot achieve a success rate significantly better than random guessing. Theorems along these lines have been proven previously, but our bound on the success rate is better than the previous bounds.
</p>